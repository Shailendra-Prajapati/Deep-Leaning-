{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizaing_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIS8LUlyizaX+eP3Zu29E8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizing a Neural Netwrok**\n",
        "Optimizing a Neural Network or any modle for that matter is like tuning a radio. The difference is there might be a million knoobs to tune simultaneously.\n"
      ],
      "metadata": {
        "id": "6HUlQJQ7rFQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "lOTkSKqMqyVp",
        "outputId": "653746da-e750-478f-c5a1-0494e2349098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "text/html": [
              "<img src=\"https://media3.giphy.com/media/l2Je32EwtM8jUnKk8/giphy.gif\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(url=\"https://media3.giphy.com/media/l2Je32EwtM8jUnKk8/giphy.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overfitting and Underfitting\n",
        "\n",
        "`Overfitting`:  is a scenario where your model performs well on training data but perform poorly on data not seen during training. This means that our model has memorized the training data instead of learning the raltionship between features and labels.\n",
        "\n",
        "`Underfitting` : It is the opposite counterpart of overfitting wherein our model exhibits high bias. This situation can occur when our model is not sufficiently complex to capture relationship between features and labels.\n",
        "\n",
        "Underfitting is a bit harder to diagnose. If Accuracy and Validation Accuracy are similar but are both poor, then you may be underfitting."
      ],
      "metadata": {
        "id": "5gnw8zryr18N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vz4336Qvr0dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## # Strategies to avoid Overfitting/Underfitting\n",
        "\n",
        "Overfitting can be handled by reducing the complexity of our model( i.e. reducing the number of trainable parameters). This is done by:\n",
        "\n",
        "  - Use fewer layes(Shallow Networks), fewer neurons per layer(Narrow Networks)\n",
        "  - Using Dropouts\n",
        "  - Using Regularization\n",
        "  - Early Stopping in some cases.\n",
        "\n",
        "Underfitting can be handled by :\n",
        "  - Increasing the complexity of our model i.e. increasing layerss and number   of  neurons. With more layers, the network can learn more sophisticated relationships and perhaps perform well on difficult real-world tasks.\n"
      ],
      "metadata": {
        "id": "ScmYHHQytVZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X7vdqCAMu2ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using MNSIT Dataset\n",
        "\n",
        "Simple example of how number of layers and number of neurons affect the model."
      ],
      "metadata": {
        "id": "5sAuBvH3y6j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## To load the graph in notebook only\n",
        "%matplotlib inline \n",
        "\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "hezNWXHXzJkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load mnsit dataset from the tensorflow library\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QooREeEO0XMW",
        "outputId": "b34bb25d-e158-40d5-d4b8-e86aed8b7751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the first 5 images and corresponding labels in our training data\n",
        "images = X_train[:5]\n",
        "labels = y_train[:5]\n",
        "\n",
        "for index, image in enumerate(images):\n",
        "  print('Label:', labels[index])\n",
        "  #argmax picks out the label with highest probability\n",
        "  print('Digit in the image', np.argmax(labels[index]))\n",
        "  plt.imshow(image.reshape(28,28), cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N4fnASai06Ds",
        "outputId": "74d5e125-cb14-4622-98e9-e43f0d7ec47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5\n",
            "Digit in the image 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0\n",
            "Digit in the image 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 4\n",
            "Digit in the image 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n",
            "Digit in the image 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9\n",
            "Digit in the image 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "## TensorBoard For Visualization\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "OckavVenerC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why did we reshaped ?\n",
        "\n",
        "As it Flattens images to 1-D vector of 784 features (28*28) i.e., it coverts the 2-D NumPy array of dimension 28*28 to a 1-D array of length 784\n"
      ],
      "metadata": {
        "id": "DUS9nz4Hjp0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reshaping of the train and test dataset \n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "trjgzfbVflBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the purpose of to_categorical ?\n",
        "\n",
        "converts a class vector(integers) to binary class matrix.\n",
        "\n",
        "`Syntax`: to_categorical(y, num_calsses=NULL, dtype=\"float32\")\n",
        "  - y: class vector to be converted into matrix\n",
        "  - num_classes: Total  number of classes\n",
        "  - dtype: The data type expexted by  the input,as a string."
      ],
      "metadata": {
        "id": "_vbSFMcBkKze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using to_categorical to converts the vetcor to binary class matrix\n",
        "\n",
        "y_train  = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "1RICXGv1kJVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SlVRt8FPl9Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Neural Network with only one input and output layer`"
      ],
      "metadata": {
        "id": "HbIiRQ0AmCVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Sequential just symbolises\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAIl0GtImL73",
        "outputId": "5e0efbec-59da-48c8-ac8d-924aed6b3833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used softmax as activation function because this is a multiclass classification.\n"
      ],
      "metadata": {
        "id": "ku6V3r5dnuK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For tensorboard visualization we can check out the following : https://www.youtube.com/watch?v=Uzkhn5ENJzQ&feature=youtu.be\n",
        "\n",
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir = logdir)\n"
      ],
      "metadata": {
        "id": "S71y2c0BnANC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history = model.fit(\n",
        "    X_train, # input\n",
        "    y_train, # output\n",
        "    batch_size= 32,\n",
        "    verbose=1, # Suppress chatty output; use Tensorboard instead\n",
        "    epochs=10, \n",
        "    validation_data=(X_test,y_test),\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xlbYfr_pDfz",
        "outputId": "00d3def4-a485-4854-efba-30b10a8ce6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 2.0283 - accuracy: 0.5056 - val_loss: 1.1739 - val_accuracy: 0.6138\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9895 - accuracy: 0.6935 - val_loss: 0.7985 - val_accuracy: 0.8013\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7143 - accuracy: 0.8028 - val_loss: 0.6424 - val_accuracy: 0.8037\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5581 - accuracy: 0.8486 - val_loss: 0.5833 - val_accuracy: 0.8547\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4871 - accuracy: 0.8680 - val_loss: 0.5737 - val_accuracy: 0.8651\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4433 - accuracy: 0.8823 - val_loss: 0.4568 - val_accuracy: 0.8871\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4187 - accuracy: 0.8876 - val_loss: 0.4578 - val_accuracy: 0.8915\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3925 - accuracy: 0.8929 - val_loss: 0.4468 - val_accuracy: 0.8923\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3748 - accuracy: 0.8979 - val_loss: 0.4739 - val_accuracy: 0.8883\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3632 - accuracy: 0.9021 - val_loss: 0.4122 - val_accuracy: 0.9060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The relative tensorboard graph is below. The maximum accuracy achieved is 0.90. If we train it for longer (for more epochs) maybe the accuracy will increase."
      ],
      "metadata": {
        "id": "e726YAHKrXSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![underfitting_validation.JPG](https://drive.google.com/uc?export=view&id=1N7odof3bwAVOwbbm73_CdKbH3gWMkp4Z)"
      ],
      "metadata": {
        "id": "L9pVKWXVshEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jsnX92Vrpwsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Adding many layers to the model`"
      ],
      "metadata": {
        "id": "iulldKYasluZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "# 10 Neurons layer\n",
        "model2.add(Dense(10, activation='relu',input_shape=(784,) ))\n",
        "\n",
        "# Many 512 Neuron Layer\n",
        "# Change the number of layers (Increase or Decrease)\n",
        "\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', \n",
        "               optimizer=SGD(lr=0.001),\n",
        "               metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kMao0lzsqX-",
        "outputId": "aa4986f6-a530-4ccb-88e9-ffc409b9ff09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir = logdir)"
      ],
      "metadata": {
        "id": "u27BA1U8txUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history= model2.fit(\n",
        "    X_train, # input\n",
        "    y_train, # output\n",
        "    batch_size = 32,\n",
        "    verbose=1, # Suppress chatty output; use TensorBoard instead\n",
        "    epochs= 10,\n",
        "    validation_data=(X_test,y_test),\n",
        "    callbacks=[tensorboard_callback] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RRHwcl8uFfl",
        "outputId": "4e45b2ea-bb93-445e-ece2-567753a23082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.6485 - accuracy: 0.7901 - val_loss: 0.3912 - val_accuracy: 0.8720\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.3169 - accuracy: 0.9002 - val_loss: 0.2919 - val_accuracy: 0.9076\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2479 - accuracy: 0.9223 - val_loss: 0.2443 - val_accuracy: 0.9247\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2157 - accuracy: 0.9323 - val_loss: 0.2100 - val_accuracy: 0.9369\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1917 - accuracy: 0.9395 - val_loss: 0.1956 - val_accuracy: 0.9411\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1749 - accuracy: 0.9447 - val_loss: 0.1885 - val_accuracy: 0.9421\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1602 - accuracy: 0.9493 - val_loss: 0.1915 - val_accuracy: 0.9408\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1492 - accuracy: 0.9527 - val_loss: 0.1778 - val_accuracy: 0.9484\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1378 - accuracy: 0.9558 - val_loss: 0.1763 - val_accuracy: 0.9454\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1292 - accuracy: 0.9583 - val_loss: 0.1745 - val_accuracy: 0.9460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![over_fitting](https://drive.google.com/uc?export=view&id=16YqSkIgM-exFGTX6drUMGjyBNjod7q6f)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "O8ijEj1MNdRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bYUx9QQLup6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Conclusion`\n",
        "\n",
        "It is clearly visible deep networks have better accuracy and vice versa. Adding more layers increases the accuracy but it might lead to **Overfitting** or **Generalisation Error**."
      ],
      "metadata": {
        "id": "uqRoxQfON315"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BtCS1W5jOxAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping\n",
        "\n",
        "When training a large network, there will be a point during training when the model will stop generalizing and start learning the statistical noise in the training dataset.\n",
        "\n",
        "This overfitting of the training dataset will result in an increase in generalization error, making the model less useful at making predictions on new data.\n",
        "\n",
        "EarlyStopping basically stops training at the point when performance on a validation dataset starts to degrade. (It would by default need a validation set to be able to work).\n"
      ],
      "metadata": {
        "id": "mZySTXSoO0Rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to get through this:\n",
        "  - Either limit the number of Epoch (not preferred)\n",
        "  - Use EarlyStoppingt Criteria(preferred)"
      ],
      "metadata": {
        "id": "P5_o7HXtPSFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "```\n",
        "`monitor` :  you can choose any metric to monitor like val_loss, val_acc. <br>\n",
        "`mode` :  by default it is auto and knows that you want to minimize loss or maximize accuracy. like *min* in case of val_loss. <br>\n",
        "`patience`: patience is the number to epochs to wait before stopping it. ex -  If we are chasing *val_loss* and we it is not reducing from the last 50 epoch we stop the training if patience is 50.<br>"
      ],
      "metadata": {
        "id": "aCD36X5nPuMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_cross', mode='min', \n",
        "                   verbose=1, patience=5)"
      ],
      "metadata": {
        "id": "An8bZOMDPQNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3= Sequential()\n",
        "\n",
        "model3.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', \n",
        "               optimizer=SGD(lr=0.001),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6peefiQJXO",
        "outputId": "f184eb86-72ff-4d43-a38c-95a5b081d5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "Wq3l20bUQ5y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history =model3.fit(\n",
        "    X_train, # input\n",
        "    y_train, # output\n",
        "    batch_size = 32,\n",
        "    verbose = 1, # Suppress chatty output; use Tensorboard instead\n",
        "    epochs = 10, \n",
        "    validation_data = (X_test, y_test),\n",
        "    callbacks = [tensorboard_callback,es]\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "-989yCsiR-Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d951a417-8b16-4644-ef78-32c3a4fb4332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9958WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.1837 - val_accuracy: 0.9573\n",
            "Epoch 2/10\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9967WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 0.1835 - val_accuracy: 0.9599\n",
            "Epoch 3/10\n",
            "1859/1875 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9974WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.1859 - val_accuracy: 0.9590\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9975WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.1868 - val_accuracy: 0.9593\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9979WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.1839 - val_accuracy: 0.9613\n",
            "Epoch 6/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.1878 - val_accuracy: 0.9593\n",
            "Epoch 7/10\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.1879 - val_accuracy: 0.9615\n",
            "Epoch 8/10\n",
            "1859/1875 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9988WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.1888 - val_accuracy: 0.9617\n",
            "Epoch 9/10\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1907 - val_accuracy: 0.9608\n",
            "Epoch 10/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9992WARNING:tensorflow:Early stopping conditioned on metric `val_cross` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1931 - val_accuracy: 0.9613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "phnwdk5YTeYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regularization\n",
        "\n",
        "Regularization is a technique which makes slight modifications to the learning algorithm such that the model generalizes better. This in turn improves the model’s performance on the unseen data as well. \n",
        "\n",
        "By adding more layers to the model (making it more complex) ? Adding more than required layers might also lead to overfitting. \n",
        "\n",
        "Graph below helps to understand what can be the ideal model."
      ],
      "metadata": {
        "id": "9EAfJe75VX_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![perfect_point.png](https://drive.google.com/uc?export=view&id=1isDRyvRtMFPhC8RQHL9Puh-OoOm0z9FP)"
      ],
      "metadata": {
        "id": "o-pIty6xVdHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is how to use it in your neural networks.\n",
        "```python\n",
        "model.add(Dense(256,activation='relu', kernel_regularizer = 'l2'))\n",
        "```"
      ],
      "metadata": {
        "id": "RluLSg6rV07z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropouts\n",
        "\n",
        "Dropout is a regularization method that approximates training a large number of neural networks with different architectures in parallel. As mentioned, it is preferrably used when training a large neural network. "
      ],
      "metadata": {
        "id": "H5rziqdEV4ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(url=\"https://miro.medium.com/max/1200/1*iWQzxhVlvadk6VAJjsgXgg.png\", width=800, height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "BqlUTI1eVYw8",
        "outputId": "3e5a09ee-c2e1-47fa-bd80-47f5af5d011f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "text/html": [
              "<img src=\"https://miro.medium.com/max/1200/1*iWQzxhVlvadk6VAJjsgXgg.png\" width=\"800\" height=\"500\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*By dropping a unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections*\n"
      ],
      "metadata": {
        "id": "pZodTjHYWH0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "s91K3FR6WCa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential()\n",
        "model4.add(Dense(10, activation='relu', input_shape= (784,) ))\n",
        "model4.add(Dropout(0.2)) ###using dropout\n",
        "model4.add(Dense(256,activation='relu', kernel_regularizer = 'l2'))###using regularizer\n",
        "model4.add(Dropout(0.2))###using dropout\n",
        "model4.add(Dense(256,activation='relu', kernel_regularizer = 'l2')) ###using regularizer\n",
        "model4.add(Dropout(0.2))###using dropout\n",
        "model4.add(Dense(10, activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo-6gpzUWZ_c",
        "outputId": "6cb87d9b-5c8c-4cb0-850c-2d9f8e111267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "metadata": {
        "id": "ILTAUcnMWjls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history = model.fit(\n",
        "    X_train, # input\n",
        "    y_train, # output\n",
        "    batch_size=32,\n",
        "    verbose=1, # Suppress chatty output; use Tensorboard instead\n",
        "    epochs=10,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[tensorboard_callback, es],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfwwy296Wmz9",
        "outputId": "719cef56-fd19-4fb5-fa94-fc0b1215d739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3468 - accuracy: 0.9067 - val_loss: 0.4167 - val_accuracy: 0.9028\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3331 - accuracy: 0.9091 - val_loss: 0.3973 - val_accuracy: 0.9056\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3262 - accuracy: 0.9115 - val_loss: 0.3776 - val_accuracy: 0.9115\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3131 - accuracy: 0.9147 - val_loss: 0.3547 - val_accuracy: 0.9174\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3077 - accuracy: 0.9166 - val_loss: 0.3519 - val_accuracy: 0.9173\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2996 - accuracy: 0.9178 - val_loss: 0.3770 - val_accuracy: 0.9125\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2935 - accuracy: 0.9198 - val_loss: 0.3715 - val_accuracy: 0.9138\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2859 - accuracy: 0.9209 - val_loss: 0.3359 - val_accuracy: 0.9226\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2812 - accuracy: 0.9231 - val_loss: 0.3484 - val_accuracy: 0.9132\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2755 - accuracy: 0.9245 - val_loss: 0.3257 - val_accuracy: 0.9233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cNHJbXxRWqQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why not just use early stopping rather than regularisation ?\n",
        "\n",
        "The main downside of early stopping is that this couples two tasks:\n",
        "\n",
        "1. Algorithm to optimize the cost function j (eg gradient descent, adam etc)\n",
        "2. Prevent overfitting (ie get more data, regularization)\n",
        "\n",
        "because by stopping gradient decent early, we are sort of breaking whatever we are doing to optimize cost function J and simultaneously trying to not over fit."
      ],
      "metadata": {
        "id": "_5DN5rOEWydD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ou21a04EWzDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Points to conclude with**\n",
        "\n",
        "- Large weights in a neural network are a sign of a more complex network that has overfit the training data.\n",
        "- Probabilistically dropping out nodes in the network is a simple and effective regularization method.\n",
        "- A large network with more training and the use of a weight constraint are suggested when using dropout."
      ],
      "metadata": {
        "id": "m7gBXZHKW2jK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qjWSfDfwW3OM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}